λ΅μ»¬ LLM + μ½”λ“ RAG μ„Έν… (Windows / νμ‡„λ§)

<img src="./aaa.png" width="1000" />

μ‚¬μ§„μ—μ„ λ³Ό μ μλ“―, μΈν„°λ„·μ΄ μ•λλ” μƒν™©μ—μ„ 

<img src="./bbb.png" width="1000" />

λ‹µλ³€μ„ ν•΄μ£Όλ” λ¨μµ. μ¦‰, LLMμ΄ λ΅μ»¬μ—μ„ λκ³ μλ”κ²ƒμ΄λ‹¤.

```plaintext
μ΄μ§ν• νμ‚¬κ°€ λ‚΄λ¶€λ§μ„ μ“°λ”λ° chatGPTλ¥Ό λ‹¤λ¥Έ μ»΄ν“¨ν„°μ—μ„ μ“°κ³  λ³µλ¶™ν•λ” κ² κ·€μ°®μ•„μ„ μ§μ ‘ μ •λ¦¬ν•¨.
USB β†’ νμ‡„λ§ PCλ΅ λ³µμ‚¬ ν›„ μ•„λ κµ¬μ΅°λ΅ μ„Έν….

-----------------------------------------π“‚ ν”„λ΅μ νΈ κµ¬μ΅°

λ¨λΈμ΄λ‘ μ„¤μΉνμΌμ€ μ•„λ§ μ‚¬μ΄μ¦κ°€ μ»¤μ„ κΉƒμ— λ»μ¬λ¦΄λ“―.
https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF?utm_source=chatgpt.com
μ— λ“¤μ–΄κ°€μ„ λ‚΄ μ»΄ν“¨ν„° μ¤ν™μ— μ—¬μ μλ” λ¨λΈλ΅ λ‹¤μ΄

νμ΄μ¬ λ‹¤μ΄κ²½λ΅λ„
https://www.python.org/downloads/release/python-3137/

ollama λ‹¤μ΄κ²½λ΅
https://ollama.com/download


C:\llm\
 β”β”€ models\
 β”‚   β”β”€ Meta-Llama-3.1-8B-Instruct-Q3_K_S.gguf   (κ°μΈPCμ©)
 β”‚   β”β”€ Meta-Llama-3.1-8B-Instruct-Q5_K_M.gguf   (νμ‚¬PCμ©)
 β”‚   β”β”€ Meta-Llama-3.1-8B-Instruct-Q6_K_L.gguf   (κ³ μ‚¬μ–‘μ©)
 β”‚   β”β”€ Modelfile-q3.txt
 β”‚   β”β”€ Modelfile-q5.txt
 β”‚   β”β”€ Modelfile-q3   β† ν™•μ¥μ μ—†λ” νμΌ
 β”‚   β””β”€ Modelfile-q5   β† ν™•μ¥μ μ—†λ” νμΌ
 β”‚
 β””β”€ tools\
     β”β”€ index_repo.py
     β”β”€ ask.py
     β””β”€ agent_apply.py    (μ„ νƒ: diff μλ™ μ μ©κΈ°)


.pyλ‚ ν™•μ¥μ μ—†λ” μƒν”μ€ λ©”λ¨μ¥μ—μ„ β€λ¨λ“  νμΌβ€ μ„ νƒ β†’ ν™•μ¥μ λ¶™μ—¬ μ €μ¥ν•΄μ„ tools/μ— λ„£μΌλ©΄ λ¨.

-----------------------------------------β™οΈ μ„Έν…
Modelfile μμ‹

C:\llm\models\Modelfile-q3.txt

FROM C:\llm\models\Meta-Llama-3.1-8B-Instruct-Q3_K_S.gguf
PARAMETER temperature 0.2
PARAMETER num_ctx 2048
PARAMETER num_gpu_layers 0


β†’ μ €μ¥ μ‹ ν™•μ¥μ μ κ±° β†’ Modelfile-q3

C:\llm\models\Modelfile-q5.txt

FROM C:\llm\models\Meta-Llama-3.1-8B-Instruct-Q5_K_M.gguf
PARAMETER temperature 0.2
PARAMETER num_ctx 4096
PARAMETER num_gpu_layers 0


β†’ μ €μ¥ μ‹ ν™•μ¥μ μ κ±° β†’ Modelfile-q5

μ„¤μΉ μμ„

Ollama μ„¤μΉ

OllamaSetup.exe μ‹¤ν–‰ (κΈ°λ³Έκ°’ μ„¤μΉ)

Python μ„¤μΉ

python-3.13.x-amd64.exe μ‹¤ν–‰

λ°λ“μ‹ "Add python.exe to PATH" μ²΄ν¬ ν›„ μ„¤μΉ

μ„¤μΉ ν™•μΈ

ollama -v
python --version

-----------------------------------------π λ¨λΈ λ“±λ΅
ollama create <μ΄λ¦„> -f <λ¨λΈνμΌκ²½λ΅>


κ°μΈPC (RAM 7~8GB):

ollama create my-llama31 -f C:\llm\models\Modelfile-q3


νμ‚¬PC (RAM 16~32GB):

ollama create my-llama31-q5 -f C:\llm\models\Modelfile-q5

π—‘ λ¨λΈ μ‚­μ 
ollama list


μ¶λ ¥ μμ‹:

NAME             ID              SIZE    MODIFIED
my-llama31       3d82f19fβ€¦       3.4 GB  2025-09-06 11:20:00
my-llama31-q5    b91a01c2β€¦       5.7 GB  2025-09-06 09:45:00


νΉμ • λ¨λΈ μ‚­μ :

ollama rm my-llama31

-----------------------------------------π€ μ‹¤ν–‰ λ°©λ²• 1
1) κ·Έλƒ¥ μ‹¤ν–‰ (λΉ λ¦„)
ollama run my-llama31

<img src="./aaa.png" width="300" />
<img src="./bbb.png" width="300" />



-----------------------------------------π€ μ‹¤ν–‰ λ°©λ²• 2
2) ν”„λ΅μ νΈ κΈ°λ° RAG μ‹¤ν–‰ (μ—„μ²­λλ¦Ό....γ… γ… )

μ„λ²„ μ‹¤ν–‰

ollama serve


μ½”λ“ μΈλ±μ‹±

cd /d C:\llm\tools
python index_repo.py --root "C:\κ²½λ΅\λ‚΄ν”„λ΅μ νΈ"


β†’ tools/code_index.json μƒμ„±

μ§λ¬Έν•κΈ° (CMD: ^ λ΅ μ¤„λ°”κΏ)

python ask.py --q "μ•λ…•? λ‚΄ ν”„λ΅μ νΈμ @@@μ— λ€ν•΄ μ•λ ¤μ¤" ^
  --api "http://127.0.0.1:11434/v1/chat/completions" ^
  --model "my-llama31"

μ§λ¬Έν•κΈ° (PowerShell: λ°±ν‹± ` λ΅ μ¤„λ°”κΏ)

python ask.py --q "μ•λ…•? λ‚΄ ν”„λ΅μ νΈμ @@@μ— λ€ν•΄ μ•λ ¤μ¤" `
  --api "http://127.0.0.1:11434/v1/chat/completions" `
  --model "my-llama31"

-----------------------------------------π›  νΈλ¬λΈ”μν…

μ¤λ¥:

Error: listen tcp 127.0.0.1:11434: bind: Only one usage of each socket address...
β†’ μ΄λ―Έ μ‹¤ν–‰ μ¤‘. ν”„λ΅μ„Έμ¤ μΆ…λ£ ν›„ ollama serve λ‹¤μ‹ μ‹μ‘.

-----------------------------------------π“ κΈ°λ΅μ‚¬ν•­

λ¨λΈ νΉμ„± λ°”κΎΈλ ¤λ©΄ ask.txtλ‚ index_repo.txt μ°Έκ³  β†’ μμ • ν›„ .pyλ΅ λ³€ν™ β†’ tools/μ— λ„£κ³  μ‹¤ν–‰

(2025/09/06) Q3 λ¨λΈ κΈ°μ¤€ λ©”λ¨λ¦¬ 90% μ‚¬μ©. κ·Έλλ„ μ½”λ“ μ½κ³  λ‹µλ³€ μ£Όλ” κ±° κ½¤ κ΄μ°®μ π†

```
